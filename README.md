# Tutor/Reviewer App

A local AI-powered tutor and reviewer application that:
1. **Uploads** PDFs and extracts their text.
2. **Embeds** text chunks using [Ollama](https://github.com/jmorganca/ollama) (e.g. `mxbai-embed-large` model).
3. **Stores** the chunks in [Qdrant](https://qdrant.tech/) for vector search.
4. Provides a **Gradio** web interface to:
   - Display an **outline** of the material (optionally generated by an LLM).
   - **Study** by reading concise summaries of selected text sections.
   - **Test** by generating multiple-choice questions (or other quiz items).
   - **Navigate** chunks (with “Previous” / “Next”) in a Chunk Viewer.

---

## Features

- **PDF Ingestion**  
  Extract text from PDFs using [pdfplumber] or a similar library.
  
- **Text Chunking**  
  Split large texts into smaller, overlapping chunks (configurable size/overlap).

- **Local Embeddings**  
  Use [Ollama Python API](https://github.com/ollama/ollama-python) to generate embeddings with a **local** model (e.g., `mxbai-embed-large`).

- **Vector Storage in Qdrant**  
  Upsert chunk embeddings + payload (`text`) into Qdrant, enabling semantic search.

- **Outline Generation**  
  (Optional) Generate an overall outline for the extracted text if it fits in your LLM’s context window.

- **Study & Test Modes**  
  - **Study**: Summaries of the selected text chunk.
  - **Test**: Multiple-choice or short-answer questions, generated by an LLM.

- **Chunk Navigation**  
  “Previous” and “Next” buttons allow you to iterate through stored chunks in Qdrant.

- **Gradio UI**  
  Easy-to-use web app with file upload, text boxes, and button triggers.

---

## Requirements

- **Python** ≥ 3.8
- **Ollama** Python package and CLI  
  - macOS (official) or Linux (experimental).  
  - `pip install ollama`  
  - [Ollama CLI installation](https://ollama.ai/docs/installation)  
  - Pull your model: `ollama pull mxbai/embed-large`
- **Qdrant** (≥ 1.12 recommended)  
  - E.g. via Docker:  
    ```bash
    docker run -p 6333:6333 qdrant/qdrant
    ```
  - Confirm the Qdrant dashboard at [http://localhost:6333/dashboard](http://localhost:6333/dashboard).
- **Python Libraries**  
  - `gradio`
  - `langchain` (if you still use certain splitting utilities)
  - `pdfplumber` (or `PyPDF2`) for PDF ingestion
  - `qdrant-client`
  - `ollama`
  - See [`requirements.txt`](#example-requirementstxt)

---

## Example `requirements.txt`

```txt
gradio==3.31.0
langchain==0.0.200
qdrant-client==1.12.5
pdfplumber==0.9.0
ollama==0.0.11
